\chapter{Sequential Recurrence Extraction Examples}
% ---------------------------------------- FAST REVERSE ----------------------------------------
\section{Fast Reverse}
\paragraph{}
Fast reverse is an implementation reverse in linear time complexity.
A naive implementation of reverse appends the head of the list to recursively
reversed tail of  the list. Fast reverse instead uses an abstraction to delay
the consing. As this is the first example, we will walk through the translation
and interpretation in gory detail.

\paragraph{}
The definition of the list datatype holds no surprises.
%
\[
  \T{datatype list} = \T{Nil of unit}\ |\ \T{Cons of int} \times \T{list}
\]
%
The implementation of fast reverse is not obvious. We write a function \T{rev}
that applies an auxiliary function to an empty list to produce the result.  The
specification of reverse is \T{rev [$x_0,\dots,x_{n-1}$] =
[$x_{n-1},\dots,x_0$]}. The specification of the auxiliary function
\T{rec(xs,$\dots$)} is \T{rec($[x_0,\dots,x_{n-1}],\dots$)
[$y_0,\dots,y_{m-1}$] = [$x_{n-1},\dots,x_0,y_0,\dots,y_{m-1}$]}.
%
\begin{lstlisting}
rev xs = $\lambda$xs.rec(xs,
               Nil $\mapsto$ $\lambda$a.a,
               Cons$\mapsto$b.split(b,x.c.split(c,xs'.r.
                        $\lambda$a.force(r) Cons$\LP$x,a$\RP$))) Nil
\end{lstlisting}
%
Notice that the implementation of \T{rev} would be much cleaner if we where
able to pattern match on cases of the \T{rec}. Below is \T{rev} written with
this syntactic sugar.
%
\begin{lstlisting}
rev = $\lambda$xs.rec(xs, Nil $\mapsto \lambda$a.a,
              Cons$\mapsto\LP$y$\LP$ys,r$\RP\RP$.$\lambda$b.force(r) Cons$\LP$x,b$\RP$) Nil
\end{lstlisting}
%
Each recursive call creates an abstraction that applies the recursive call on
the tail of the list to the list created by consing the head of the list onto
the abstraction argument. The recursive calls builds nested abstractions as
deep as the length of the list which is collapsed by application of the
outermost abstraction to \T{Nil}. Below we show the evaluation of \T{rev}
applied to a small list of just two elements.
%
\begin{lstlisting}
rev (Cons$\LP$0,Cons$\LP$1, Nil$\RP\RP$) $\to$
  rec(Cons$\LP$0,Cons$\LP$1,Nil$\RP\RP$,
      Nil $\mapsto\lambda$a.a
      Cons$\mapsto$b.split(b,x.c.split(c,xs'.r.
               $\lambda$a.force(r) Cons$\LP$x,a$\RP$))) Nil
  $\to^*_\beta (\lambda$a0.($\lambda$a1.($\lambda$a2.a2) Cons$\LP$1,a1$\RP$) Cons$\LP$0,a0$\RP$) Nil
  $\to_\beta$ ($\lambda$a1.($\lambda$a2.a2) Cons$\LP$1,a1$\RP$) Cons$\LP$0,Nil$\RP$
  $\to_\beta$ ($\lambda$a2.a2) Cons$\LP$1,Cons$\LP$0,Nil$\RP\RP$
  $\to_\beta$ Cons$\LP$1,Cons$\LP$0,Nil$\RP\RP$
\end{lstlisting}
%
% -------------------- BEGIN REV TRANSLATION SPLIT --------------------
\subsection{Translation}
We will walk through the translation from the source language to the complexity
language.
%
\begin{flalign*}
  \|\T{rev}\| &= \|\lambda xs.\T{rec}(xs, \T{Nil}\mapsto\lambda\T{a.a,} \\
              &\quad \T{Cons}\mapsto b.\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP\T{x,a}\RP)))\ \T{Nil}\| \\
\end{flalign*}
%
% BEGIN ABSTRACTION
%
First we apply the rule for translating an abstraction. The rule is
$\|\lambda x. e\| = \LP 0, \lambda x. \|e\|\RP$.
%
\begin{flalign*}
  \|\T{rev}\| &= \|\lambda xs.\T{rec}(xs, \T{Nil} \mapsto\lambda a.a, \\
              &\quadthree \T{Cons}\mapsto b.\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r) \T{Cons}\LP x,a\RP)))\ \T{Nil}\| \\
              &\quad = \LP 0, \lambda xs.\|\T{rec}(xs, \T{Nil}\mapsto\lambda a.a, \\
              &\quadthree \T{Cons}\mapsto b.\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r) \T{Cons}\LP x,a\RP)))\ \T{Nil}\|\RP \\
\end{flalign*}
%
The next translation is an application. The rule for translating an application is
$\|e_0\ e_1\| = (1 + \|e_0\|_c + \|e_1\|_c) +_c (\|e_0\|_p\ \|e_1\|_p)$.
In this case, \T{rec(...)} is $e_0$ and \T{Nil} is $e_1$. We translate \T{Nil} then
\T{rec(...)} separately.
%
% APP ARGUMENT
%
The translation of a constructor applied to an expression is a tuple of the
cost of the translated expression and the corresponding complexity language
constructor applied to the potential of the translated expression. Since the
expression inside \T{Nil} is $\LP\RP$, and
$\|\LP\RP\| = \LP 0,\LP\RP\RP$, we have
%
\begin{flalign*}
  |\T{Nil}\| &= \LP\LP 0, \LP\RP\RP_c, \T{Nil}\LP 0,\LP\RP\RP_p\RP \\
             &= \LP 0, \T{Nil}\LP\RP\RP
\end{flalign*}
%
% BEGIN REC
%
The rule for translating a \T{rec} expression is
\[
  \|\T{rec}(e,\overline{C \mapsto x.e_C})\| = \|e\|_c +_c \T{rec}(\|e\|_p, \overline{C \mapsto x.\|e_C\|})
\]
%
\begin{flalign*}
  &\|\T{rec}(xs, \T{Nil}\mapsto\lambda a.a, \\
  &\qquad \T{Cons}\mapsto b.\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP)))\| \\
  &= \|xs\|_c +_c \T{rec}(\|xs\|_p, \T{Nil} \mapsto 1 +_c \|\lambda a.a\| \\
  &\quadthree \T{Cons}\mapsto b. 1 +_c \|\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP))\|) \\
  &= \LP 0, xs \RP_c +_c \T{rec}(\LP 0, xs\RP_p, \T{Nil} \mapsto 1 +_c \|\lambda a.a\| \\
  &\quadthree \T{Cons}\mapsto b. 1 +_c \|\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP))\|) \\
  &\text{The term $xs$ is a variable and the rule for translating variables is $\|xs\| = \LP 0, xs\RP$.} \\
  &= \T{rec}(xs, \T{Nil} \mapsto 1 +_c \|\lambda a.a\| \\
  &\quadthree \T{Cons}\mapsto b. 1 +_c \|\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP))\|)
\end{flalign*}
%
% NIL BRANCH
%
The translation of the \T{Nil} branch is
simple application of the $\|\lambda x.e\| = \LP 0, \lambda
x.\|e\|\RP$ and the variable translation rule.
%
\begin{flalign*}
  &1 +_c \|\lambda a.a\| \\
  &= 1  +_c   \LP 0, \lambda a. \| a \|\RP \\
  &=  \LP 1, \lambda a. \LP 0,a \RP\RP
\end{flalign*}
%
% BEGIN CONS BRANCH
%
The translation of the \T{Cons} branch is a slightly more involved. The rule
for translating \T{split} is
%
\[ \|\T{split}(e_0,x_0.x_1.e_1)\| = \|e_0\|_c +_c \|e_1\|[\pi_0\|e_0\|_p/x_0, \pi_1\|e_0\|_p/x_1] \]
%
After applying the rule to the \T{Cons} branch we get
%
\begin{flalign*}
  &1 +_c \|\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons} \LP x,a \RP )) \| \\
  &= 1 +_c \|b\|_c +_c \|\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a \RP) \|[\pi_0 \| b \|_p/x,\pi_1 \| b \|_p/c]
\end{flalign*}
%
Remember that $b$ is a variable and has type
$\phi_\T{Cons}[\T{list} \times \T{susp (list} \to \T{list)}]$.
The translation of this type is
$\textbf{C} \times \llangle \phi_\T{Cons} \rrangle [\T{list} \times \LP \T{list} \to \LP \textbf{C} \times \T{list} \RP\RP]$.
We can say that \T{$\pi_0\|$b$\|_p$} is the head of the list \T{xs},
\T{$\pi_0\pi_1\|$b$\|_p$} is the tail of the list \T{xs}, and
\T{$\pi_1\pi_1\|$b$\|_p$} is the result of the recursive call.
The translation of $b$ is $\LP 0, b\RP$.
%
\begin{flalign*}
  &1 +_c \|b\|_c +_c \|\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a \RP) \|[\pi_0 \| b \|_p/x,\pi_1 \| b \|_p/c] \\
  &=1 +_c \|\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a \RP) \|[\pi_0 \| b \|_p/x,\pi_1 \| b \|_p/c] \\
  %
  &\qquad \text{We apply the rule for \T{split} again.} \\
  %
  &=1 +_c (\|c\|_c +_c \|\lambda a.\T{force}(r)\ \T{Cons}\LP x,a \RP\|[\pi_0 \|c\|_p/xs', \pi_1\|c\|_p/r][\pi_0 \| b \|_p/x,\pi_1 \| b \|_p/c] \\
  %
  &\qquad \text{$c$ is a variable, so its translation is $\LP 0, c \RP$.} \\
  %
  &=1 +_c \|\lambda a.\T{force}(r)\ \T{Cons}\LP x,a \RP\|[\pi_0 \|c\|_p/xs', \pi_1\|c\|_p/r][\pi_0 \| b \|_p/x,\pi_1 \| b \|_p/c] \\
  %
  &\qquad \text{We apply the rule for abstraction.} \\
  %
  &=1 +_c \LP 0, \lambda a.\|\T{force}(r)\ \T{Cons}\LP x,a \RP\|[\pi_0 \|c\|_p/xs', \pi_1\|c\|_p/r][\pi_0 \| b \|_p/x,\pi_1 \| b \|_p/c] \\
  %
  &\qquad \text{Recall $C +_c E$ is a macro for $\LP C + E_c, E_p\RP$. We use this to eliminate the $+_c$.} \\
  &\qquad \text{We also apply the translation rule for application.} \\
  %
  &=\LP 1, \lambda a.(1 + \|\T{force}(r)\|_c + \|\T{Cons}\LP x,a\RP\|_c) \\
  &\quadfive +_c \|\T{force}(r)\|_p \|\T{Cons}\LP x,a \RP\|_p\RP[\pi_0 \|c\|_p/xs', \pi_1\|c\|_p/r][\pi_0 \| b \|_p/x,\pi_1 \| b \|_p/c] \\
\end{flalign*}
%
% COMPOSE SUBSTITUTIONS
%
\begin{flalign*}
  &\text{We will translate $\T{force}(r)$ and $\T{Cons}\LP x,a\RP$ individually.} \\
  &\text{First we compose the two substitutions.} \\
  %
  &\text{let } \Theta = [\pi_0 \|c\|_p/xs', \pi_1\|c\|_p/r][\pi_0 \| b \|_p/x,\pi_1 \| b \|_p/c] \\
  &\quadthree = [\pi_0\pi_1 \|b\|_p/xs', \pi_1\pi_1\|b\|_p/r, \pi_0 \| b \|_p/x] \\
  &\quad \text{Since $b$ is a variable, the potential  of its translation is $b$.} \\
  &\Theta = [\pi_0\pi_1 b/xs', \pi_1\pi_1 b/r, \pi_0 b/x] \\
\end{flalign*}
%
% FORCE
%
\begin{flalign*}
  &\quad \text{In translation of $\T{force}(r)$ we apply the rule $\|\T{force}(e)\| = \|e\|_c +_c \|e\|_p$.}\\
  &\quadthree \|\T{force}(r)\|\Theta = \|r\|_c\Theta +_c \|r\|_p\Theta \\
  %
  &\quad \text{We apply the variable translation rule to $r$, then apply the substitution $\Theta$.}\\
  %
  &\quadfive = \LP 0, r \RP_c\Theta +_c \LP 0, r \RP_p \Theta \\
  &\quadfive = r\Theta = \pi_1\pi_1 b \\
\end{flalign*}
%
% CONS
%
\begin{flalign*}
  &\quad \text{Next we do the translation of $\T{Cons}\LP x,a \RP$.} \\
  &\quadthree \|\T{Cons}\LP x, a\RP\| = \LP \|\LP x,a \RP\|_c, \T{Cons} \|\LP x,a \RP\|_p\RP \\
  %
  &\quad \text{Notice the translation of $\LP x,a \RP$ appears twice, so we will do this separately.} \\
  %
  &\quadfour \|\LP x,a \RP\| = \LP \|x\|_c + \|a\|_c, \LP \|x\|_p, \|a\|_p \RP \RP \Theta\\
  %
  &\quad \text{Both $x$ and $a$ are variables, so they have $0$ cost.}\\
  %
  &\quadsix = \LP 0, \LP x, a \RP\RP \Theta\\
  %
  &\quad \text{We apply the substitution $\Theta$.}\\
  %
  &\quadsix = \LP 0, \LP \pi_1 b, \pi_1\pi_1 b \RP\RP \\
  %
  &\quadsix = \LP 0, \LP \pi_1 b, \pi_1\pi_1 b \RP\RP \\
  %
  &\quad \text{We complete the translation of $\T{Cons}\LP x, a\RP$ using $\LP x, a \RP$.} \\
  %
  &\quadthree \|\T{Cons}\LP x, a\RP\| = \LP \|\LP x,a \RP\|_c, \T{Cons} \|\LP x,a \RP\|_p\RP \\
  &\quadfive = \LP 0, \T{Cons} \LP \pi_1 b, \pi_1\pi_1 b \RP\RP \\
\end{flalign*}
%
% END CONS BRANCH
%
\begin{flalign*}
  &\quad \text{We use substitute in the translations of $\T{force}(r)$ and $\T{Cons}\LP x, a\RP$.}\\
  &\quad \text{$\|\T{force}(r)\|$ has cost $(\pi_1\pi_1 b)_c$ and $\|\T{Cons}\LP x,a\RP\|$ has cost $0$.}\\
  &\LP 1, \lambda a.(1 + \|\T{force}(r)\|_c + \|\T{Cons}\LP x,a\RP\|_c) +_c \|\T{force}(r)\|_p \|\T{Cons}\LP x,a \RP\|_p\RP \RP\Theta \\
  %
  &= \LP 1, \lambda a.(1 + (\pi_1\pi_1 b)_c) +_c (\pi_1\pi_1 b)_p\ \T{Cons}\LP \pi_1 b, a \RP\RP \\
\end{flalign*}
%
% END REC
%
\begin{flalign*}
  &\text{We can now complete the translation of the \T{rec} expression.} \\
  &\|\T{rec}(xs, \T{Nil}\mapsto\lambda a.a, \\
  &\qquad \T{Cons}\mapsto b.\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP)))\| \\
  &= \T{rec}(xs, \T{Nil} \mapsto 1 +_c \|\lambda a.a\| \\
  &\quadthree \T{Cons}\mapsto b. 1 +_c \|\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP))\|) \\
  &= \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0,a \RP\RP \\
  &\quadthree \T{Cons}\mapsto b.\LP 1, \lambda a.(1 + (\pi_1\pi_1 b)_c) +_c (\pi_1\pi_1 b)_p\ \T{Cons}\LP \pi_1 b, a \RP\RP) \\
\end{flalign*}
%
% END APP FUNCTION
%
\begin{flalign*}
  &\text{We substitute the translation of \T{rec} and \T{Nil} into the translation of the application.}\\
  &\text{Let }R = \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0,a \RP\RP \\
  &\quadfive \T{Cons}\mapsto b.\LP 1, \lambda a.(1 + (\pi_1\pi_1 b)_c) +_c (\pi_1\pi_1 b)_p\ \T{Cons}\LP \pi_1 b, a \RP\RP) \\
  &\|\T{rec}(xs, \T{Nil}\mapsto\lambda a.a, \\
  &\qquad \T{Cons}\mapsto b.\T{split}(b,x.c.\T{split}(c,xs'.r.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP)))\ \T{Nil}\| \\
  &\text{Substituting $R$ for the translation of \T{rec} and $\LP 0, \T{Nil}\RP$ for the translation of \T{Nil}.} \\
  &\quad = (1 + R_c) +_c R_p\ \T{Nil} \RP\\
  &\text{Recall }C +_c E = \LP C + E_c, E_p \RP, \text{ so } (1 + E_c) +_c E_p = 1 +_c E \\
  &\quad = 1 +_c \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0,a \RP\RP \\
  &\quadthree \T{Cons}\mapsto b.\LP 1, \lambda a.(1 + (\pi_1\pi_1 b)_c) +_c (\pi_1\pi_1 b)_p\ \T{Cons}\LP \pi_1 b, a \RP\RP)\ \T{Nil}\\
\end{flalign*}
%
% END APP
%
\begin{flalign*}
  &\text{Finally, we substitute this into the translation of \T{rev}.} \\
  \|\T{rev}\| &= \|(\lambda\T{xs.rec(xs, Nil}\mapsto\lambda\T{a.a,} \\
              &\quad \T{Cons}\mapsto\T{b.split(b,x.c.split(c,xs'.r.}\lambda\T{a.force(r) Cons}\LP\T{x,a}\RP\T{)))) Nil}\| \\
  &\quad = \LP 0, \lambda xs. 1 +_c \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0,a \RP\RP \\
  &\quadthree \T{Cons}\mapsto b.\LP 1, \lambda a.(1 + (\pi_1\pi_1 b)_c) +_c (\pi_1\pi_1 b)_p\ \T{Cons}\LP \pi_1 b, a \RP\RP)\ \T{Nil}\RP\\
\end{flalign*}
%
% END REV TRANSLATION SPLIT
%
Observe that $\|\T{rev}\|$ admits the same syntactic sugar as \T{rev}. In the
complexity language, instead of taking projections of $b$, we can use the same
pattern matching syntactic sugar as in the source language.

\begin{flalign*}
  &\|\T{rev}\| = \LP 0, \lambda xs. 1 +_c \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0,a \RP\RP \\
  &\quadthree \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP.\LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP \pi_1 x, a \RP\RP)\ \T{Nil}\RP\\
\end{flalign*}


%
% FAST REVESE TRANSLATION USING SYNTACTIC SUGAR
%
\subsection{Syntactic Sugar Translation}
%
We walk through the same translation of fast reverse, but we use the syntactic
sugar for matching introduced earlier. Recall the implementation of fast using
syntactic sugar. The translation is almost identical to the translation of \T{rev}
written without syntactic sugar until we translate the \T{Cons} branch of the
\T{rec}.
%
\begin{flalign*}
  \|\T{rev}\| &= \|\lambda\T{xs.rec(xs, Nil}\mapsto\lambda\T{a.a,} \\
              &\quad \T{Cons}\mapsto\LP x, \LP xs', r\RP\RP.\lambda a.\T{force}(r)\ \T{Cons}\LP x, a\RP)\ \T{Nil}\|
\end{flalign*}
%
First we apply the rule for translating an abstraction. The rule is
$\|\lambda x. e\| = \LP 0, \lambda x. \|e\|\RP$.
%
\begin{flalign*}
  \|\T{rev}\| &= \LP 0, \lambda xs. \|\T{rec}(xs, \T{Nil}\mapsto\lambda a.a, \\
              &\quad \T{Cons}\mapsto\LP x, \LP xs', r\RP\RP.\lambda a.\T{force}(r)\ \T{Cons}\LP x, a\RP)\ \T{Nil}\|\RP
\end{flalign*}
%
%
% BEGIN APP
%
Next we apply the rule for translating an application. The rule is
$\|e_0\ e_1\| = (1 + \|e_0\|_c + \|e_1\|_c) +_c (\|e_0\|_p\ \|e_1\|_p)$.
In this case, \T{rec(...)} is $e_0$ and \T{Nil} is $e_1$. We translate
\T{Nil} then \T{rec(...)} separately.
%
% APP ARGUMENT
%
The translation of a constructor applied to an expression is a tuple of the
cost of the translated expression and the corresponding complexity language
constructor applied to the potential of the translated expression. Since the
expression inside \T{Nil} is $\LP\RP$, and
$\|\LP\RP\| = \LP 0,\LP\RP\RP$, we have
%
\begin{flalign*}
  \|\T{Nil}\| &= \LP\LP 0, \LP\RP\RP_c, \T{Nil}\LP 0,\LP\RP\RP_p\RP \\
             &= \LP 0, \T{Nil}\LP\RP\RP
\end{flalign*}
%
% BEGIN REC
%
The rule for translating a \T{rec} expression is
\[
  \|\T{rec}(e,\overline{C \mapsto x.e_C})\| = \|e\|_c +_c \T{rec}(\|e\|_p, \overline{C \mapsto x.\|e_C\|})
\]
%
\begin{flalign*}
  &\|\T{rec}(xs, \T{Nil}\mapsto\lambda a.a, \\
  &\qquad \T{Cons}\mapsto \LP x,\LP xs',r \RP\RP.\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP)\| \\
  &= \|xs\|_c +_c \T{rec}(\|xs\|_p, \T{Nil} \mapsto 1 +_c \|\lambda a.a\| \\
  &\quadthree \T{Cons}\mapsto \LP x,\LP xs',r \RP\RP.1 +_c \|\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP\|) \\
  &= \LP 0, xs \RP_c +_c \T{rec}(\LP 0, xs\RP_p, \T{Nil} \mapsto 1 +_c \|\lambda a.a\| \\
  &\quadthree \T{Cons}\mapsto \LP x,\LP xs',r \RP\RP.1 +_c \|\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP\|) \\
  &\text{The term $xs$ is a variable and the rule for translating variables is $\|xs\| = \LP 0, xs\RP$.} \\
  &= \T{rec}(xs, \T{Nil} \mapsto 1 +_c \|\lambda a.a\| \\
  &\quadthree \T{Cons}\mapsto \LP x,\LP xs',r \RP\RP.1 +_c \|\lambda a.\T{force}(r)\ \T{Cons}\LP x,a\RP\|) \\
\end{flalign*}
%
% NIL BRANCH
%
The translation of the \T{Nil} branch is the same as before.
%
\begin{flalign*}
  &1 +_c \|\lambda a.a\| =  \LP 1, \lambda a. \LP 0,a \RP\RP
\end{flalign*}
%
% BEGIN CONS BRANCH
%
The translation of the \T{Cons} branch is much simpler without the two \T{split}s.
%
\begin{flalign*}
  &1 +_c \|\lambda a.\T{force}(r)\ \T{Cons}\LP x, a\RP\| \\
  &\quad = 1 +_c \LP 0, \lambda a.\|\T{force}(r)\ \T{Cons}\LP x, a\RP\|\RP \\
  &\quad = \LP 1, \lambda a.(1 + \|\T{force}(r)\|_c + \|\T{Cons}\LP x, a\RP)\|_c) +_c \|\T{force}(r)\|_p\ \|\T{Cons}\LP x, a \RP\|_p \RP \\
\end{flalign*}
%
The translation of $\T{force}(r)$ and $\T{Cons}\LP x, a \RP$
are the same as before, except we do not have a substitution to apply.
%
\begin{flalign*}
  &\|\T{force}(r)\| = \|r\|_c +_c \|r\|_p = \LP 0, r \RP_c +_c \LP 0, r \RP_p = 0 +_c r = r
\end{flalign*}
%
\begin{flalign*}
  &\|\T{Cons}\LP x, a\RP\| =  \LP 0, \T{Cons} \LP x, a \RP\RP \\
\end{flalign*}
%
So the complete translation of the \T{Cons} branch is
%
\begin{flalign*}
  &1 +_c \|\lambda a.\T{force}(r)\ \T{Cons}\LP x, a\RP\| \\
  &\quad = 1 +_c \LP 0, \lambda a.\|\T{force}(r)\ \T{Cons}\LP x, a\RP\|\RP \\
  &\quad = \LP 1, \lambda a.(1 + \|\T{force}(r)\|_c + \|\T{Cons}\LP x, a\RP)\|_c) +_c \|\T{force}(r)\|_p\ \|\T{Cons}\LP x, a \RP\|_p \RP \\
  &\quad = \LP 1, \lambda a.(1 + r_c + 0) +_c r_p\ \T{Cons}\LP x, a \RP \RP \\
  &\quad = \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP \\
\end{flalign*}
%
The complete translation of the \T{rec} becomes
%
\begin{flalign*}
  &\|\T{rec}(xs, \T{Nil}\mapsto\lambda a.a, \\
  &\qquad \T{Cons}\mapsto  \LP x, \LP xs', r\RP\RP.\lambda a.\T{force}(r)\ \T{Cons}\LP x, a\RP)\| \\
  &= \T{rec}(xs, \T{Nil} \mapsto 1 +_c \|\lambda a.a\| \\
  &\quadthree \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP.1 +_c \|\lambda a.\T{force}(r)\ \T{Cons}\LP x, a\RP\|) \\
  &= \T{rec}(xs, \T{Nil} \mapsto \LP 0, \lambda a. \LP 0, a \RP \RP \\
  &\quadthree \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP. \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP \\
\end{flalign*}
%
We substitute the translations of \T{rec(..)} and \T{Nil} into the application.
%
\begin{flalign*}
  &\text{Let }R = \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0, a \RP \RP \\
  &\quadthree \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP. \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP \\
  &\|\T{rec}(xs, \T{Nil}\mapsto\lambda a.a, \\
  &\qquad \T{Cons}\mapsto \LP x, \LP xs',r \RP\RP.\lambda a.\T{force}(r)\ \T{Cons}\LP x, a \RP)\ \T{Nil}\| \\
  &\text{Substituting $R$ for the translation of \T{rec} and $\LP 0, \T{Nil}\RP$ for the translation of \T{Nil}.} \\
  &\quad = (1 + R_c) +_c R_p\ \T{Nil} \RP\\
  &\quad = 1 +_c \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0, a \RP \RP \\
  &\quadthree \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP. \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP)\ \T{Nil} \\
\end{flalign*}
%
And our complete translation of \T{rev} is
%
\begin{flalign*}
  \|\T{rev}\| &= \|\lambda\T{xs.rec(xs, Nil}\mapsto\lambda\T{a.a,} \\
              &\qquad \T{Cons}\mapsto\LP x, \LP xs', r\RP\RP.\lambda a.\T{force}(r)\ \T{Cons}\LP x, a\RP)\ \T{Nil}\| \\
              &= \LP 0, \lambda xs. \|\T{rec}(xs, \T{Nil}\mapsto\lambda a.a, \\
              &\quad \T{Cons}\mapsto\LP x, \LP xs', r\RP\RP.\lambda a.\T{force}(r)\ \T{Cons}\LP x, a\RP)\ \T{Nil}\| \RP \\
              &= \LP 0, \lambda xs. 1 +_c \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0, a \RP \RP \\
              &\qquad \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP. \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP)\ \T{Nil} \RP\\
\end{flalign*}
%
This is the same as the translation of \T{rev} without the syntactic sugar. We
will use the syntactic sugar for the rest of this thesis.
%
% END FAST REVERSE SYNTACTIC SUGAR TRANSLATION
%
%
% ============= FAST REVERSE INTERPRETATION ====================
%
\subsection{Interpretation}
%
The interpretation of \T{rev} is not interesting as the cost of \T{rev} is always null.
Instead of interpreting \T{rev}, we will interpret \T{rev} applied to a list \T{xs}.
Below is the translation of \T{rev xs}.
%
\begin{flalign*}
  &\|\T{rev xs}\| = (1 + \|\T{rev}\|_c + \|xs\|_c) +_c \|\T{rev}\|_p\ \|xs\|_p \\
  &\text{The cost of $\|\T{rev}\|$ is $0$, and we will let \T{xs} be a value, which has $0$ cost.} \\
  &= (1 + 0 + 0) +_c \|\T{rev}\|_p\ xs \\
  &= 1 +_c (\lambda xs. 1 +_c \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0, a \RP \RP \\
  &\qquad \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP. \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP)\ \T{Nil})\ xs\\
\end{flalign*}
%
The cost of \T{rev} is driven by the auxiliary function \T{rec(...)}. The cost
of \T{rev} will be determined by the cost of the auxiliary function \T{rec(...)}
applied to \T{Nil} plus some constant factor. We will interpret the auxiliary
function in the following denotational semantics.


Since \T{list} is a user defined datatype, we must provide an interpretation.
We interpret the size of an \T{list} to be the number of list constructors.
%
\begin{flalign*}
  \LB \T{list} \RB &= \mathbb{N}^\infty\\
  D^{list} &= \{\ast\} + \{1\} \times \mathbb{N}^\infty\\
  size_{list}(\T{Nil}) &= 1\\
  size_{list}(\T{Cons(1,n)}) &= 1 + n\\
\end{flalign*}
%
We define the macro $R(xs)$ as the translation of the auxiliary function
\T{rec(...)} to avoid repeated coping of the translation.
%
\begin{flalign*}
  &\text{Let } R(xs) = \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0, a \RP \RP \\
  &\quadfive \T{Cons}\mapsto b. \LP 1, \lambda a.(1 + \pi_1\pi_1 b_c) +_c \pi_1\pi_1 b_p\ \T{Cons}\LP \pi_0 b, a \RP \RP \\
\end{flalign*}
%
The recurrence $g(n)$ is the interpretation of the auxiliary function $R(xs)$,
where $n$ is the interpretation of $xs$.
%
\begin{flalign*}
  &g(n) = \LB R(xs) \RB \{xs \mapsto n\} \\
  &= \bigvee\limits_{size\ z \leq \LB xs \RB \{xs \mapsto n\}} case(z, f_C, f_N) \\
  &\text{where} \\
  &f_{Nil}(x) = \LB \LP 1, \lambda a. \LP 0, a\RP\RP \RB \{xs \mapsto n\} \\
  &\qquad = (1, \lambda a.(0, a)) \\
  &f_{Cons}(b) = \LB \LP 1, \lambda a.(1 + \pi_1\pi_1 b_c) +_c \pi_1\pi_1 b_p\ \T{Cons}\LP \pi_0 b, a \RP \RP \RB \\
  &\quadfive \{xs \mapsto n, b \mapsto map^{\Phi_{Cons}}(d.(d, \LB R(w) \RB \{ w \mapsto d, xs \mapsto n \}), b) \} \\
\end{flalign*}
%
Let us take a moment to analyze the semantic $map$. The definition mirrors the
definition of the \T{map} macro in the complexity language. Since $b$ is a
tuple, $map$ over a tuple is defined as the tuple of the $map$ over the
projections of the
tuple.
%
\begin{flalign*}
  &\qquad map^{\Phi_{Cons}}(d.(d, \LB R(w) \RB \{ w \mapsto d \}), b) \\
  &\qquad = (map^{int}(d.(d, \LB R(w) \RB \{w \mapsto d\}), \pi_0 b), \\
  &\quadfour map^{list}(d.(d, \LB R(w) \RB \{w \mapsto d\}), \pi_1 b)) \\
  %
  &\text{The definition of $map$ over $int$ is $map^{int}(\lambda x.V_0, V_1) = V_1$.}\\
  &\qquad = (\pi_0 b, map^{list}(d.(d, \LB R(w) \RB \{w \mapsto d\}), \pi_1 b)) \\
  %
  &\text{The definition of $map$ over a recursive occurrence of a }\\
  &\text{a datatype is $map^T(x.V_0,V_1) = V_0[V_1/x]$.} \\
  &\qquad = (\pi_0 b, (\pi_1 b, \LB R(w) \RB \{w \mapsto \pi_1 b\})) \\
  %
  &\text{Observe that we can substitute $g(\pi_1 b)$ for $\LB R(w) \RB \{w \mapsto \pi_1 b\}$.} \\
  &\qquad = (\pi_0 b, (\pi_1 b, g(\pi_1 b))) \\
\end{flalign*}
%
Let us resume our interpretation of \T{rec(...)}.
%
\begin{flalign*}
  &f_{Cons}(b) = \LB \LP 1, \lambda a.(1 + \pi_1\pi_1 b_c) +_c \pi_1\pi_1 b_p\ \T{Cons}\LP \pi_0 b, a \RP \RP \RB \\
  &\quadfive \{xs \mapsto n, b \mapsto map^{\Phi_{Cons}}(\lambda d.(d, \LB R(w) \RB \{ w \mapsto d\}), b) \} \\
  &\quad = \LB \LP 1, \lambda a.(1 + \pi_1\pi_1 b_c) +_c \pi_1\pi_1 b_p\ \T{Cons}\LP \pi_0 b, a \RP \RP \RB \\
  &\quadfive \{xs \mapsto n, b \mapsto (\pi_0 b, (\pi_1 b, g(\pi_1 b))) \} \\
  &\quad = (1, \LB \lambda a.(1 + \pi_1\pi_1 b_c) +_c \pi_1\pi_1 b_p\ \T{Cons}\LP \pi_0 b, a \RP \RB \\
  &\quadfive \{xs \mapsto n, b \mapsto (\pi_0 b, (\pi_1 b, g(\pi_1 b))) \}) \\
  &\quad = (1, \lambda a. \LB (1 + \pi_1\pi_1 b_c) +_c \pi_1\pi_1 b_p\ \T{Cons}\LP \pi_0 b, a \RP \RB \\
  &\quadfive \{xs \mapsto n, b \mapsto (\pi_0 b, (\pi_1 b, g(\pi_1 b))), a \mapsto a \}) \\
  &\quad = (1, \lambda a. (1 + g_c(\pi_1 b)) +_c g_p(\pi_1 b)\ (1 + a))\\
\end{flalign*}
%
So the initial extracted recurrence from \T{rec} is
%
\begin{flalign*}
  &g(n) = \bigvee\limits_{size\ z \leq n} case(z, f_C, f_N) \\
  &\text{where} \\
  &f_{Nil}(x) = (1, \lambda a.(0, a)) \\
  &f_{Cons}(b) = (1, \lambda a. (1 + g_c(\pi_1 b)) +_c g_p(\pi_1 b)\ (a + 1))\\
\end{flalign*}
%
To obtain a closed form solution for the recurrence, we must eliminate the big
maximum operator. To do so we break the definition of $g$ into two cases.
%
\begin{description}
  \item[case $n=0$]\hfill \\
    For $n=0$, $g(0) = (1,\lambda a.(0,a))$.
  \item[case $n>0$]\hfill \\
    \begin{align*}
      g(n+1) &= \bigvee_{size\ ys \leq n+1} case(ys, f_{Nil}, f_{Cons}) \\
             &= \bigvee_{size\ ys \leq n} case(ys, f_{Nil}, f_{Cons}) \vee \bigvee_{size\ ys = n+1} case(ys, f_{Nil}, f_{Cons}) \\
             &= g(n) \vee \bigvee_{size\ ys = n+1} case(ys, \lambda().(1,\lambda a.( 0,a)), \\
             &\quadten \lambda (1,m).(1, \lambda a.(1 + g_c(m)) +_c g_p(m) (a+1))) \\
             &= g(n) \vee \LP 1, \lambda a. (1 + g_c(n)) +_c g_p(n) (a+1))) \\
    \end{align*}
\end{description}
%
In order to eliminate the remaining max operator, we want to show that $g$ is
monotonically increasing; $\forall n.g(n) \leq g(n+1)$.
By definition of $\leq$,
$g(n) \leq g(n+1) \Leftrightarrow g_c(n) \leq g_c(n+1) \land g_p(n) \leq g_p(n+1)$.
First we will show lemma \ref{lem:fr_interp_g_cost_one}, which states the cost
of $g(n)$ is always one.
%
\begin{lemma}
  \label{lem:fr_interp_g_cost_one}
  $\forall n. g_c(n) = 1$.
\end{lemma}
%
\begin{proof}
We prove this by induction on $n$.
  \begin{description}
    \item[Base case: $n=0$]\hfill \\
      By definition, $g_c(0) = (1, \lambda a.(0,a)) = 1$.
    \item[Induction step: $n>0$]\hfill \\
      By definition $g_c(n+1) = (g(n) \vee (1, \lambda a. (1 + g_c(n)) +_c g_p(n)\ (a+1)))_c$.
      We distribute the projection over the max: $g_c(n+1) = g_c(n) \vee 1$.
      By the induction hypothesis, $g_c(n) = 1$, so $g_c(n+1) = 1$.
  \end{description}
\end{proof}
%
The immediate corollary of this is $g_c(n)$ is monotonically increasing.
%
\begin{corollary}
  \label{lem:fr_interp_g_cost_monotonically_increasing}
  $\forall n. g_c(n) \leq g_c(n+1)$.
\end{corollary}
%
First we prove the lemma stating the potential of $g(n)\ a$ is monotonically
increasing.
%
\begin{lemma}
  \label{lem:fr_interp_g_potential_monotonically_increasing}
  $\forall n.g_p(n)\ a \leq g_p(n)\ (a+1)$
\end{lemma}
%
\begin{proof}
  We prove this by induction on $n$.
  \begin{description}
    \item[$n=0$]\hfill \\
      $g_p(0)\ a = (\lambda a.(0,a))\ a = (0,a)$\\
      $g_p(0)\ (a+1) = (\lambda a.(0.a))\ (a+1) = (0,a+1)$\\
      $(0,a) \leq (0,a+1)$.
    \item[$n>0$]\hfill \\
      We assume $g_p(n)\ a \leq g_p(n)\ (a+1)$.
      \begin{align*}
      g_p(n)\ a &\leq g_p(n)\ (a+1)  \\
      g_p(n)\ a \vee (1 + g_c(n)) +_c g_p(n)\ a &\leq g_p(n)\ (a+1) \vee (1 + g_c(n)) +_c g_p(n)\ (a+1) \\
      g_p(n+1)\ a &\leq g_p(n+1)\ (a+1)
      \end{align*}
  \end{description}
\end{proof}
%
Now we show $g_p(n) \leq g_p(n+1)$.
%
\begin{proof}
  By reflexivity, $g_p(n) \leq g_p(n)$.
  By the lemma we just proved:
  \begin{align*}
  g_p(n)\ a &\leq g_p(n)\ (a+1) \\
  g_p(n)\ a &\leq (1 + g_c(n)) +_c g_p(n)\ (a+1) \\
  %\[ \pi_1 g(n) a \leq \LP 2 + \pi_0 (\pi_1 g(n) (a+1)), \pi_1 (\pi_1 g(n) (a+1)) \RP \]
  \lambda a.g_p(n)\ a &\leq \lambda a. (1 + g_c(n)) +_c g_p(n)\ (a+1)
  \end{align*}
\end{proof}
%
So since for all $n$, $g_c(n) = 1$ and $g_p(n) \leq \lambda a. (1 + g_c(n)) +_c g_p(n)\ (a+1)$, we conclude
%
\begin{flalign*}
  g(n) &\leq \LP 1, \lambda a. (1 + g_c(n)) +_c g_p(n)\ (a+1)\RP) \\
\end{flalign*}
%
So
%
\begin{flalign*}
  g(n+1) &= \LP 1, \lambda a. (1 + g_c(n)) +_c g_p(n)\ (a+1)\RP\\
\end{flalign*}
%
%
To extract a recurrence from $g$, we apply $g$ to the interpretation of a list $a$.
%
Let $h(n,a) = g_p(n)\ a$.
%
For $n=0$
%
\begin{align*}
  h(0,a) &= g_p(0) a \\
         &= (\lambda a.(0,a)) a \\
         &= (0, a)
\end{align*}
%
For $n>0$
%
\begin{align*}
  h(n,a) &= g_p(n) a \\
         &= (\lambda a. (1 + g_c(n-1)) +_c g_p(n-1)\ (a+1))\ a \\
         &= (1 + g_c(n-1)) +_c g_p(n-1) (a+1) \\
         &= (1 + 1) +_c h(n-1,a+1) \\
         &= (2 + h_c(n-1,a+1), h_p(n-1,a+1))
\end{align*}
%
From this recurrence, we can extract a recurrence for the cost.
%
For $n=0$
%
\begin{align*}
h_c(0,a) &= (0, a)_c = 0
\end{align*}
%
For $n>0$
%
\begin{align*}
  h_c(n,a) &= (2 + h_c(n-1,a+1), h_p(n-1,a+1))_c = 2 + h_c(n-1,a+1)
\end{align*}
%
We now have a recurrence for the cost of the auxiliary function
\T{rec(xs,$\dots$)} when applied to some list:
%
\begin{equation}
  h_c(n,a) = \begin{cases}
    0 & n = 0 \\
    2 + h_c(n-1,a+1) & n > 0
  \end{cases}
\end{equation}
%
We state the solution to the recurrence $h_c$ is $2n$.
%
\begin{theorem}
  \label{lem:fr_interp_h_cost}
  $h_c(n,a) = 2n$
\end{theorem}
%
\begin{proof}
  We prove this by induction on $n$.
  \begin{description}
    \item{case $n=0$}\hfill \\
      $h_c(0,a) = 0 = 2 \cdot 0$
    \item{case $n>0$}\hfill \\
      We assume $h_c(n,a+1) = 2n$.
      \begin{align*}
        h_c(n+1,a) &= 2 + h_c(n,a+1) \\
                   &= 2 + 2n  \\
                   &= 2(n+1)
      \end{align*}
  \end{description}
\end{proof}
%
So we have proved the interpretation of applying the auxiliary function of
\T{rev xs} to a list is linear in the length of \T{xs}.



We can also extract a recurrence for the potential.
For $n=0$
%
\begin{align*}
h_p(0,a) &= h_p(0,a) \\
         &= (0, a)_p \\
         &= a
\end{align*}
%
For $n>0$
%
\begin{align*}
  h_p(n,a) &= (2 + h_c(n-1,a+1), h_p(n-1,a+1))_p \\
           &= h_p(n-1,a+1)
\end{align*}
%
We now have a recurrence for the potential of the auxiliary function in
\T{rev xs} when applied to some list $a$.
%
\begin{equation}
  h_p(n,a) = \begin{cases}
    a & n = 0 \\
    h_p(n-1,a+1) & n > 0
  \end{cases}
\end{equation}
%
\begin{theorem}
  \label{lem:fr_interp_h_potential}
  $h_p(n,a) = n + a$
\end{theorem}
%
\begin{proof}
  We prove this by induction on $n$.
  \begin{description}
    \item{case $n=0$}\hfill \\
      \[ h_p(0,a) = a \]
    \item{case $n>0$}\hfill \\
      \begin{align*}
      h_p(n,a) &= h_p(n-1,a+1) \\
               &= n - 1 + a + 1  \qquad \text{by the induction hypothesis} \\
               &= n + a
      \end{align*}
  \end{description}
\end{proof}
%

% ===================================================================================================

Now that we have obtained a closed form solution for the recurrence describing
the cost and potential of the auxiliary function that drives the cost of
\T{rev}, we can obtain the interpretations for the cost and potential of \T{rev xs}.
Recall the translation of \T{rev xs}.
%
\begin{flalign*}
  \|\T{rev xs}\| &= 1 +_c (\lambda xs. 1 +_c \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0, a \RP \RP \\
  &\qquad \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP. \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP)\ \T{Nil})\ xs
\end{flalign*}
%
We can obtain an interpretation of $\|\T{rev xs}\|$ by substituting our
interpretation of the auxiliary function.
%
\begin{flalign*}
  &\text{Let $n = \LB \|xs\| \RB.$}\\
  \LB\|\T{rev xs}\|\RB &= \LB 1 +_c (\lambda xs. 1 +_c \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0, a \RP \RP\\
  &\qquad \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP. \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP)\ \T{Nil})\ xs \RB \{xs \mapsto n\}  \\
  &= 1 +_c \LB \lambda xs. 1 +_c \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0, a \RP \RP\\
  &\qquad \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP. \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP)\ \T{Nil} \RB \{xs \mapsto n\}\ n  \\
  &= 1 +_c (\lambda xs. \LB 1 +_c \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0, a \RP \RP\\
  &\qquad \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP. \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP)\ \T{Nil}\RB \{xs \mapsto n\})\ n  \\
  &= 1 +_c (\lambda xs. 1 +_c \LB \T{rec}(xs, \T{Nil} \mapsto \LP 1, \lambda a. \LP 0, a \RP \RP\\
  &\qquad \T{Cons}\mapsto \LP x, \LP xs', r\RP\RP. \LP 1, \lambda a.(1 + r_c) +_c r_p\ \T{Cons}\LP x, a \RP \RP)\RB \{xs \mapsto n\}\ 0)\ n  \\
  &= 1 +_c (\lambda xs. 1 +_c h(xs,0))\ n  \\
  &= 1 +_c (1 +_c h(n,0)) \\
  &= 1 +_c (1 +_c (2n,n)) \\
  &= (2 + 2n,n)
\end{flalign*}

So we see that the cost of \T{rev xs} is linear in the length of the list, and
that the potential of the result is equal to the potential of the input.
